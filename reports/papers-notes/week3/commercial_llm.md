# [Commercial LLM Vulnerabilities](commercial-llm.pdf)
> Li, Ang, et al. "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks." *arXiv preprint arXiv:2502.08586* (2025).
## Overview
LLM agents are susceptible to many of the same attacks as LLMs, but the tools that agents are provided can lead to new types of attacks. Not enough research has been done on the security of LLM agents, and as such already deployed agents (ie commercial agents) are very easy to attack with little to no knowledge on the specifics of the model or ML in general. This paper attacks personal agents like Anthropic's Computer Use and MultiOn agents, as well as research agents like ChemChrow, and shows how easy it is for attacks to circumvent existing security measures.
## Web agent attacks
Many agents that have access to web search have restrictions on which websites they're allowed to access. This paper explores attacks where external attackers put untrusted websites in posts on trusted websites (eg reddit posts), and create an environment (eg a jailbreaking prompt, manipulated images, other websites, etc) to get the LLM agent to visit the link and complete given instructions. Whenever a user searches for something related, the post comes up and the agent visits the trusted site. They then are directed by the adversarial environment to execute the attack: this may be disclosing PII, downloading malware, sending phising emails to contacts, etc. The paper describes two such attacks. 
### Disclosing information
The attacker sets up an innocuous reddit post about a fake fridge. When the user asks the web agent to look around for fridges, the agent comes across this post, with a link to a website that contains a jailbreaking prompt and form to put in credit card information. The authors found that their attack was 100% effective, even with a simple and obvious jailbreaking prompt. When the authors tried the same attack with simply the URL (not the reddit posting), they found the attack failed every time.
### Running files
The authors also propose a similar attack where the link points to a fake VPN site with a download to malware. In this attack, they make sure that the website includes many red flags and hosted the VPN on a suspicious website. Despite this, the attack was still 100% successful in their trials.
### Email phishing
A third attack the authors tried involved an email client. The setup is the same (finding a reddit post), but the jailbreaking prompt this time instructed the agent to email close contacts to the user asking for money. They tested this in scenarios where the user was already logged in and when the user wasn't, but their credentials were within the system prompt. Once again, they found 100% success in their testing.
## Research Agents
The last attack type the authors show is one involving ChemCrow, a research agent that helps build certain chemicals and compounds.
### RAG poisoning
ChemCrow uses RAG to generate recipes for materials. An attack the authors tried was placing a modified recipe for an existing compound, such that the new recipe would create a dangerous substance, into the database that ChemCrow pulls from. They then labeled it the best recipe for this compound. When people searched for the best recipe for the compound, the modified recipe appeared, even though there were far more recipes that used standard methods. The database also did not detect these modifications as being harmful.
### Bypassing Guardrails
ChemCrow has some guardrails put in place, like detecting requests for certain dangerous compounds. These guardrails are not very thorough, though, as this next attack shows. If you ask ChemCrow to generate nerve gas for you, then it will refuse. If you ask it to generate the same thing, but using the International Union of Pure and Applied Chemistry (IUPAC) nomenclature, it generates the nerve gas.

## Questions
- How do you prevent this? You can always put in more guardrails, but how can you always be sure it is enough? There must be a way to validate RAG data and training data such that attackers cannot use obscure names
- How do you validate suspicious links that are on trusted ones? Is making sure these links are safe the responsibility of the agent or the creator of the trusted site (eg reddit)? An idea I have would be to use a LM to see if these are trustworthy (much like asking a human if the website is trustworthy), but of course that's not 100% secure.
- Could you introduce intermediate steps in the agent's action sequence so that it checks itself to make sure everything it does is safe? For example, could you have the agent ask if a link looks good before blindly visiting it, even if there's a jailbreaking prompt that tells it to visit it?